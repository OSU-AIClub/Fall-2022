{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Starter Code\n",
    "Use this code as a template, starting place, or inspiration... whatever helps you get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "This starter code will be using the following packages:\n",
    "- `Pandas`\n",
    "- `NumPy`\n",
    "- `PyTorch`\n",
    "- `nltk`\n",
    "Be sure to install these using either `pip` or `conda`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\natha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "Visit [https://www.kaggle.com/competitions/osuaiclub-fall2022-nlp-challenge/data](https://www.kaggle.com/competitions/osuaiclub-fall2022-nlp-challenge/data) to download the dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "We will be using the `pandas` package to load in our data. All the data is conveniently stored in a `.csv` file which is really easy to construct a `pandas` dataframe out of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"2nd day on 5mg started to work with rock hard...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"He pulled out, but he cummed a bit in me. I t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" I Ve had  nothing but problems with the Kepp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"I had Crohn's with a resection 30 years ago a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Have a little bit of a lingering cough from a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>Awful awful awful.  Length.  Came to top of wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>VERY SMALL. COULDN'T USE AS GIFT AS INTENDED.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>Very thin material. Good for summer, spring an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>Says Navy. Looks black.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>These shrunk after the first wash and they run...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sentiment\n",
       "id                                                                  \n",
       "0       \"2nd day on 5mg started to work with rock hard...          0\n",
       "1       \"He pulled out, but he cummed a bit in me. I t...          0\n",
       "2       \" I Ve had  nothing but problems with the Kepp...          0\n",
       "3       \"I had Crohn's with a resection 30 years ago a...          0\n",
       "4       \"Have a little bit of a lingering cough from a...          0\n",
       "...                                                   ...        ...\n",
       "999995  Awful awful awful.  Length.  Came to top of wa...          0\n",
       "999996      VERY SMALL. COULDN'T USE AS GIFT AS INTENDED.          0\n",
       "999997  Very thin material. Good for summer, spring an...          0\n",
       "999998                            Says Navy. Looks black.          0\n",
       "999999  These shrunk after the first wash and they run...          0\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), index_col='id')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Subset of Dataset for Quicker Experimentation\n",
    "We recommend using and triaining on a small subset of the dataset while you are prototyping and trying to get your model to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>\"I've been on the pill a couple months now and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>\"I've had problems with sleep for around 7-8 y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>\"Been taking Daily 4+ years living normal life...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8741</th>\n",
       "      <td>\"My mother is 88 and has had a problem with Am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10041</th>\n",
       "      <td>\"Have used Flonase for the last year - I used ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998544</th>\n",
       "      <td>Shoes are great!!  Very comfortable.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998834</th>\n",
       "      <td>Love It ! Fits comfortable and perfect!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998906</th>\n",
       "      <td>Great cross training shoe. Absolutely love the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999439</th>\n",
       "      <td>I love them!  They are very soft and warm on t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999761</th>\n",
       "      <td>I have wide feet and these fit perfect. comfy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sentiment\n",
       "id                                                                  \n",
       "1988    \"I've been on the pill a couple months now and...          1\n",
       "2062    \"I've had problems with sleep for around 7-8 y...          1\n",
       "7912    \"Been taking Daily 4+ years living normal life...          1\n",
       "8741    \"My mother is 88 and has had a problem with Am...          0\n",
       "10041   \"Have used Flonase for the last year - I used ...          1\n",
       "...                                                   ...        ...\n",
       "998544               Shoes are great!!  Very comfortable.          1\n",
       "998834            Love It ! Fits comfortable and perfect!          1\n",
       "998906  Great cross training shoe. Absolutely love the...          1\n",
       "999439  I love them!  They are very soft and warm on t...          1\n",
       "999761  I have wide feet and these fit perfect. comfy ...          1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the size of the dataset\n",
    "num_samples = len(train_df.index)\n",
    "\n",
    "# Define how many samples we want in our smaller dataset\n",
    "target_num_samples = 1000\n",
    "\n",
    "# Calculate how many training samples we need to remove\n",
    "n_remove = num_samples - target_num_samples\n",
    "\n",
    "# Randomly choose the n_remove indices we will remove\n",
    "drop_indices = np.random.choice(train_df.index, n_remove, replace=False)\n",
    "train_df = train_df.drop(drop_indices)\n",
    "\n",
    "# Show the remaining dataframe\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Class Imbalance in Dataset\n",
    "This dataset heavily favors the `1` sentiment, which represents a positive sentiment. This results in there being significantly more positive training samples than there are negative training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    653\n",
       "0    347\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will address this imbalance with [undersampling](https://machinelearningmastery.com/undersampling-algorithms-for-imbalanced-classification/) by reducing the number of positive sentiment samples in the dataset at random until it matches the number of negative sentiment samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define values for positive and negative sentiment\n",
    "POSITIVE_SENTIMENT = 1\n",
    "NEGATIVE_SENTIMENT = 0\n",
    "\n",
    "# Count the number of positive and negative samples\n",
    "num_pos_samples = train_df['sentiment'].value_counts()[POSITIVE_SENTIMENT] \n",
    "num_neg_samples = train_df['sentiment'].value_counts()[NEGATIVE_SENTIMENT]\n",
    "\n",
    "# Calculate the number of positive samples we need to remove to have \n",
    "# the same number as negative samples \n",
    "num_pos_remove = num_pos_samples - num_neg_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>\"I've been on the pill a couple months now and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>\"I've had problems with sleep for around 7-8 y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14619</th>\n",
       "      <td>\"I applied this cream twice daily, after clean...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17107</th>\n",
       "      <td>\"So far works better than anything else I've t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30052</th>\n",
       "      <td>\"Hello fellow subscribers,\\nI am a new member ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995509</th>\n",
       "      <td>I like it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996264</th>\n",
       "      <td>Exactly as expected, fast shipping</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996609</th>\n",
       "      <td>Perfect for multiple holes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998834</th>\n",
       "      <td>Love It ! Fits comfortable and perfect!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998906</th>\n",
       "      <td>Great cross training shoe. Absolutely love the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sentiment\n",
       "id                                                                  \n",
       "1988    \"I've been on the pill a couple months now and...          1\n",
       "2062    \"I've had problems with sleep for around 7-8 y...          1\n",
       "14619   \"I applied this cream twice daily, after clean...          1\n",
       "17107   \"So far works better than anything else I've t...          1\n",
       "30052   \"Hello fellow subscribers,\\nI am a new member ...          1\n",
       "...                                                   ...        ...\n",
       "995509                                          I like it          1\n",
       "996264                 Exactly as expected, fast shipping          1\n",
       "996609                         Perfect for multiple holes          1\n",
       "998834            Love It ! Fits comfortable and perfect!          1\n",
       "998906  Great cross training shoe. Absolutely love the...          1\n",
       "\n",
       "[347 rows x 2 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the Dataset into Dataframes of Postive and Negative Only Samples\n",
    "pos_df = train_df[train_df['sentiment'] == POSITIVE_SENTIMENT]\n",
    "neg_df = train_df[train_df['sentiment'] == NEGATIVE_SENTIMENT]\n",
    "\n",
    "# Randomly caluclate the postive dataframe indeces to remove\n",
    "pos_drop_indices = np.random.choice(pos_df.index, num_pos_remove, replace=False)\n",
    "\n",
    "# Drop Selected Samples from the Positive Dataframe to balance out both sentiment values\n",
    "pos_undersampled = pos_df.drop(pos_drop_indices)\n",
    "pos_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    347\n",
       "1    347\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the negative samples and the positive samples into one dataframe\n",
    "balanced_train_df = pd.concat([neg_df, pos_undersampled])\n",
    "\n",
    "# Check the counts to make sure the classes are now even\n",
    "balanced_train_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Val, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "train_val_set, test_set = train_test_split(balanced_train_df, test_size=0.20)\n",
    "train_set, val_set = train_test_split(train_val_set, test_size=0.125)\n",
    "\n",
    "# Save these splits for later use\n",
    "train_set.to_csv(os.path.join(DATA_DIR, 'train_set.csv'))\n",
    "val_set.to_csv(os.path.join(DATA_DIR, 'val_set.csv'))\n",
    "test_set.to_csv(os.path.join(DATA_DIR, 'test_set.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Now that we have created the training and testing split for our data, we can use techniques like tokenization to make the dataset easier for our model to process and train on. We will only be showing how to apply tokenization, but we encourage you to try other techniques!\n",
    "\n",
    "We will be using the PyTorch torchtext libary to achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a \"Vocabulary\"\n",
    "Next, we need to create a \"vocabulary\" of all words in the dataset. In NLP, a vocabulary is the mapping of each word to a unique ID. We will represent words in numerical form for the model to be able to interpret them.\n",
    "\n",
    "By creating this mapping, one can write a sentence with numbers. For instance, if the vocab is as follows:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"i\": 0,\n",
    " \"the\": 1,\n",
    " \"ate\": 2,\n",
    " \"pizza\": 3\n",
    "}\n",
    "```\n",
    "\n",
    "We can say \"I ate the pizza\" by saying `[0, 2, 1, 3]`.\n",
    "\n",
    "This is an oversimplified explanation of encoding, but the general idea is the same.\n",
    "\n",
    "\n",
    "`<START>` and `<END>` represent the start and end of the sample respectively. They are tokens used to identify the beginning and ending of each sentence in order to train the model. As shown, they will be inserted at the beginning and end of each sample.\n",
    "\n",
    "`<UNK>` is the token used to represent any word not in our vocabulary. This is most useful when you want to limit the vocabulary size to increase the speed of training or run inference on text never seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.datapipes.iter import FileOpener, IterableWrapper\n",
    "\n",
    "def row_processer(row):\n",
    "    return (row[1], row[2]) # [1]: text, [2]: sentiment\n",
    "\n",
    "def build_datapipe(split):\n",
    "    datapipe = IterableWrapper([os.path.join(DATA_DIR, f\"{split}.csv\")])\n",
    "    datapipe = FileOpener(datapipe, mode='b')\n",
    "    datapipe = datapipe.parse_csv(delimiter=\",\", skip_lines=1)\n",
    "    datapipe = datapipe.shuffle()\n",
    "    datapipe = datapipe.map(row_processer)\n",
    "    \n",
    "    return datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dp = build_datapipe('train_set')\n",
    "val_dp = build_datapipe('val_set')\n",
    "test_dp = build_datapipe('test_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable\nThis exception is thrown by __iter__ of CSVParserIterDataPipe(fmtparams={'delimiter': ','}, source_datapipe=FileOpenerIterDataPipe)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:514\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    516\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\iter\\fileopener.py:68\u001b[0m, in \u001b[0;36mFileOpenerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 68\u001b[0m     \u001b[39myield from\u001b[39;00m get_file_binaries_from_pathnames(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:90\u001b[0m, in \u001b[0;36mget_file_binaries_from_pathnames\u001b[1;34m(pathnames, mode, encoding)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string type for pathname, but got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m                     \u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(pathname)))\n\u001b[1;32m---> 90\u001b[0m \u001b[39myield\u001b[39;00m pathname, StreamWrapper(\u001b[39mopen\u001b[39;49m(pathname, mode, encoding\u001b[39m=\u001b[39;49mencoding))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/processed_train.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\natha\\Documents\\Programming\\AI Club\\Fall-2022\\Kaggle Competition\\SentimentAnalysisStarterCode.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/natha/Documents/Programming/AI%20Club/Fall-2022/Kaggle%20Competition/SentimentAnalysisStarterCode.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m dp:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natha/Documents/Programming/AI%20Club/Fall-2022/Kaggle%20Competition/SentimentAnalysisStarterCode.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(sample)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/natha/Documents/Programming/AI%20Club/Fall-2022/Kaggle%20Competition/SentimentAnalysisStarterCode.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:514\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    516\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     request \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:115\u001b[0m, in \u001b[0;36mMapperIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[0;32m    116\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_fn(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:514\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    516\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     request \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combinatorics.py:122\u001b[0m, in \u001b[0;36mShufflerIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[T_co]:\n\u001b[0;32m    121\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enabled:\n\u001b[1;32m--> 122\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatapipe:\n\u001b[0;32m    123\u001b[0m             \u001b[39myield\u001b[39;00m x\n\u001b[0;32m    124\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:514\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    513\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 514\u001b[0m     response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39;49msend(\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    516\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     request \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\natha\\miniconda3\\envs\\nlp\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\plain_text_reader.py:153\u001b[0m, in \u001b[0;36m_CSVBaseParserIterDataPipe.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Union[D, Tuple[\u001b[39mstr\u001b[39m, D]]]:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mfor\u001b[39;00m path, file \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_datapipe:\n\u001b[0;32m    154\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mskip_lines(file)\n\u001b[0;32m    155\u001b[0m         stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_helper\u001b[39m.\u001b[39mdecode(stream)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\datapipes\\_typing.py:534\u001b[0m, in \u001b[0;36mhook_iterator.<locals>.wrap_generator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mthrown by __iter__ of\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m full_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdatapipe\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m_generate_input_args_string(datapipe)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 534\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(e\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m msg \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m e\u001b[39m.\u001b[39;49margs[\u001b[39m0\u001b[39;49m]:\n\u001b[0;32m    535\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mThis exception is \u001b[39m\u001b[39m{\u001b[39;00mfull_msg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,) \u001b[39m+\u001b[39m e\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:]\n\u001b[0;32m    536\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'int' is not iterable\nThis exception is thrown by __iter__ of CSVParserIterDataPipe(fmtparams={'delimiter': ','}, source_datapipe=FileOpenerIterDataPipe)"
     ]
    }
   ],
   "source": [
    "for sample in dp:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data Processing Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.vocab import vocab\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "\n",
    "MAX_INPUT_LEN = 0\n",
    "\n",
    "for (text, sentiment) in dp:\n",
    "    counter.update(tokenizer(text))\n",
    "\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = vocab(counter, min_freq = 1, specials=('\\<UNK\\>', '\\<START\\>', '\\<END\\>', '\\<PAD\\>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[vocab[token] for token in \"this is an example\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline('here is an example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pipeline('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DataLoader Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def pad_tensor(t):\n",
    "     t = torch.tensor(t)\n",
    "     padding = max(MAX_INPUT_LEN) - t.size()[0]\n",
    "     t = nn.functional.pad(t, (0, padding))\n",
    "     return t\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    \n",
    "    for (_text, _label) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = torch.stack([pad_tensor(t) for t in text_list])\n",
    "    \n",
    "    return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model\n",
    "Now we can create a model and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        print(text.shape)\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        output, hidden = self.rnn(embedded)\n",
    "        print(output.shape, hidden.shape)\n",
    "        #output = [sent len, batch size, hid dim]\n",
    "        #hidden = [1, batch size, hid dim]\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 1\n",
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 400\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dl = DataLoader(train_dp, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "val_dl = DataLoader(val_dp, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dp, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (labels, text) in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        predictions = model(text).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, labels)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for (labels, text) in iterator:\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, labels)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_dl, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, val_dl, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78495c176dcf7610bcdecaf3a7823a54fa8238d5432e6157930bbc78e0bf3e46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
